{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml  \n",
    "  \n",
    "# 读取YAML文件  \n",
    "with open('config.yaml', 'r', encoding='utf-8') as file:  \n",
    "    config = yaml.safe_load(file)  \n",
    "  \n",
    "# 提取字段  \n",
    "ROOT_DIR = config['project_base_dir']  \n",
    "ShapeNet_path = config['dataset']['ShapeNet_path'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch\n",
    "from data_utils.ShapeNetDataLoader import PartNormalDataset\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import importlib\n",
    "from tqdm import tqdm\n",
    "import yaml  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    '''参数解析'''\n",
    "    parser = argparse.ArgumentParser('PointNet')\n",
    "    parser.add_argument('--batch_size', type=int, default=24, help='测试时的批处理大小')\n",
    "    parser.add_argument('--gpu', type=str, default='0', help='指定GPU设备')\n",
    "    parser.add_argument('--num_point', type=int, default=2048, help='点云中的点数')\n",
    "    parser.add_argument('--log_dir', type=str, required=True, help='实验的根目录')\n",
    "    parser.add_argument('--normal', action='store_true', default=False, help='是否使用法线信息')\n",
    "    parser.add_argument('--num_votes', type=int, default=3, help='通过投票聚合分割分数的次数')\n",
    "    parser.add_argument('--ply_file', type=str, required=True, help='待测试的PLY文件路径')\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ply(ply_file, num_point):\n",
    "    \"\"\"读取PLY文件并将点云数据预处理成模型输入格式\"\"\"\n",
    "    pcd = o3d.io.read_point_cloud(ply_file)\n",
    "    points = np.asarray(pcd.points)\n",
    "    \n",
    "    # 如果点云的点数大于 num_point，随机抽取 num_point 个点；否则填充到 num_point\n",
    "    if len(points) > num_point:\n",
    "        indices = np.random.choice(len(points), num_point, replace=False)\n",
    "        points = points[indices]\n",
    "    elif len(points) < num_point:\n",
    "        padding = np.zeros((num_point - len(points), 3))\n",
    "        points = np.vstack((points, padding))\n",
    "    \n",
    "    # 归一化处理\n",
    "    points -= np.mean(points, axis=0)\n",
    "    points /= np.max(np.sqrt(np.sum(points**2, axis=1)))\n",
    "    \n",
    "    return torch.from_numpy(points).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: PointNet [-h] [--batch_size BATCH_SIZE] [--gpu GPU]\n",
      "                [--num_point NUM_POINT] --log_dir LOG_DIR [--normal]\n",
      "                [--num_votes NUM_VOTES] --ply_file PLY_FILE\n",
      "PointNet: error: the following arguments are required: --log_dir, --ply_file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main(args):\n",
    "    # 定义一个内部函数 log_string，用于记录日志信息并将信息打印到控制台\n",
    "    def log_string(str):\n",
    "        logger.info(str)\n",
    "        print(str)\n",
    "\n",
    "    '''HYPER PARAMETER'''\n",
    "    # 设置CUDA可见的设备（指定使用的GPU）, 根据命令行参数设置\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "    # 检查是否有可用的CUDA设备, 并设置计算设备（GPU或CPU）\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and args.gpu != '-1' else \"cpu\")\n",
    "    experiment_dir = 'log/part_seg/' + args.log_dir\n",
    "\n",
    "    '''\n",
    "    日志设置\n",
    "    '''\n",
    "    logger = logging.getLogger(\"Model\")\n",
    "    logger.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    file_handler = logging.FileHandler('%s/eval.txt' % experiment_dir)\n",
    "    file_handler.setLevel(logging.INFO)\n",
    "    file_handler.setFormatter(formatter)\n",
    "    logger.addHandler(file_handler)\n",
    "    log_string('PARAMETER ...')\n",
    "    log_string(args)\n",
    "\n",
    "    # 加载测试数据集\n",
    "    root = ShapeNet_path\n",
    "    TEST_DATASET = PartNormalDataset(root=root, npoints=args.num_point, split='test', normal_channel=args.normal)\n",
    "    testDataLoader = torch.utils.data.DataLoader(TEST_DATASET, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
    "    log_string(\"The number of test data is: %d\" % len(TEST_DATASET))\n",
    "    \n",
    "    num_classes = 16\n",
    "    num_part = 50\n",
    "\n",
    "    '''MODEL LOADING'''\n",
    "    model_name = os.listdir(experiment_dir + '/logs')[0].split('.')[0]\n",
    "    MODEL = importlib.import_module(model_name)\n",
    "    classifier = MODEL.get_model(num_part, normal_channel=args.normal).to(device)\n",
    "    checkpoint = torch.load(str(experiment_dir) + '/checkpoints/best_model.pth')\n",
    "    classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_metrics = {}\n",
    "        total_correct = 0\n",
    "        total_seen = 0\n",
    "        total_seen_class = [0 for _ in range(num_part)]\n",
    "        total_correct_class = [0 for _ in range(num_part)]\n",
    "        shape_ious = {cat: [] for cat in seg_classes.keys()}\n",
    "        seg_label_to_cat = {label: cat for cat in seg_classes.keys() for label in seg_classes[cat]}\n",
    "\n",
    "        classifier = classifier.eval()\n",
    "\n",
    "        # 读取和测试PLY文件\n",
    "        ply_points = load_ply(args.ply_file, args.num_point)\n",
    "        ply_points = ply_points.unsqueeze(0).to(device)  # 添加批次维度\n",
    "\n",
    "        # 获取标签为0的虚拟标签\n",
    "        ply_label = torch.zeros(1, args.num_point).long().to(device)\n",
    "        \n",
    "        # 初始化投票池\n",
    "        vote_pool = torch.zeros(1, args.num_point, num_part).to(device)\n",
    "        for _ in range(args.num_votes):\n",
    "            seg_pred, _ = classifier(ply_points, ply_label)\n",
    "            vote_pool += seg_pred\n",
    "        \n",
    "        # 计算最终的预测结果\n",
    "        seg_pred = vote_pool / args.num_votes\n",
    "        cur_pred_val = seg_pred.cpu().data.numpy().squeeze()\n",
    "        predicted_labels = np.argmax(cur_pred_val, axis=1)\n",
    "\n",
    "        # 打印和记录预测结果\n",
    "        log_string('PLY file prediction:')\n",
    "        log_string(predicted_labels)\n",
    "\n",
    "        # 计算和记录测试指标\n",
    "        # (请根据需要计算准确率和IoU，下面的代码只是示例)\n",
    "        total_correct += np.sum(predicted_labels == ply_label.cpu().data.numpy().squeeze())\n",
    "        total_seen += args.num_point\n",
    "        test_metrics['accuracy'] = total_correct / float(total_seen)\n",
    "\n",
    "        log_string('Accuracy is: %.5f' % test_metrics['accuracy'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312forPointNet2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
